 # Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization

The course forays into the practical aspects of Deep Learning and covers the practicalitites that needs to kept in mind while building a Neural Network.
It covers the various hyperparameters available at our disposal, optimisation algorithms and practical techniques like Batch Gradient Descent and Batch Normalization to aid our implementation of Neural Networks. 

Instructor: Andrew Ng, DeepLearning.ai

1. Week1 - [Practical Aspects of Deep Learning](https://github.com/kalpak92/DeepLearningAI_ImprovingDeepNeuralNetworksHyperparameters/tree/master/Week1)
2. Week2 - [Optimization algorithms](https://github.com/kalpak92/DeepLearningAI_ImprovingDeepNeuralNetworksHyperparameters/tree/master/Week2)
3. Week3 - [Hyperparameter tuning, Batch Normalization and Programming Frameworks](https://github.com/kalpak92/DeepLearningAI_ImprovingDeepNeuralNetworksHyperparameters/tree/master/Week3)
